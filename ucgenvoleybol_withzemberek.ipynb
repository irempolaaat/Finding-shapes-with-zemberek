{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "2kJo9UWkZTWl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = open(\"/content/output.csv\",\"r\", encoding='utf-8').read()\n",
        "#print(data[:500])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.classify import ClassifierI\n",
        "from statistics import mode\n",
        "import pickle\n"
      ],
      "metadata": {
        "id": "jrmE1ejWZm2j"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install TurkishStemmer\n",
        "!pip install zemberek-python\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "import random\n",
        "import re\n",
        "from TurkishStemmer import TurkishStemmer\n",
        "from zemberek import (\n",
        "    TurkishSentenceNormalizer,\n",
        "    TurkishMorphology,\n",
        "    TurkishTokenizer,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdwmoXrEAFFi",
        "outputId": "b8ce7a9b-2338-4b0d-9634-37955ed49008"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: TurkishStemmer in /usr/local/lib/python3.10/dist-packages (1.3)\n",
            "Requirement already satisfied: zemberek-python in /usr/local/lib/python3.10/dist-packages (0.2.3)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.10/dist-packages (from zemberek-python) (4.8)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from zemberek-python) (1.26.4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = TurkishTokenizer.DEFAULT\n",
        "turkish_stopwords = stopwords.words(\"turkish\")\n",
        "stemmer = TurkishStemmer()\n",
        "morphology = TurkishMorphology.create_with_defaults()\n",
        "normalizer = TurkishSentenceNormalizer(morphology)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaJPggd6CbAb",
        "outputId": "d4f969f7-fabc-4fd5-f87a-415509a01023"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:zemberek.morphology.turkish_morphology:TurkishMorphology instance initialized in 29.653531789779663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-29 14:35:53,517 - zemberek.morphology.turkish_morphology - INFO\n",
            "Msg: TurkishMorphology instance initialized in 29.653531789779663\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import os\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "pattern = r\"\\s+[^\\sa-zA-Z0-9ğüşöçıĞÜŞİÖÇ,]\"\n",
        "document = re.sub(pattern, \"\", data)\n",
        "print(document[:100])\n",
        "lines = document.split(\"\\n\")\n",
        "document = document.replace(lines[0] + '\\n', '', 1)\n",
        "#print(document)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mbe3mgdMZmz7",
        "outputId": "331b3130-00c0-42da-ae81-8d0562331e9c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Command, Label\n",
            "Çizgi formasyonunu yap,Cizgi\n",
            "V çiz,V\n",
            "Ok başı yapıver,Ok başı\n",
            "Üçgen olun,Üçgen\n",
            "Çizgi ç\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents = []\n",
        "all_words = []\n",
        "for r in document.split(\"\\n\"):\n",
        "  #print(r)\n",
        "  if \",\" in r:\n",
        "    command_part, label = r.rsplit(\",\", 1)\n",
        "    #print(command_part, label)\n",
        "    pattern_new = r\"[^\\sa-zA-Z0-9ğüşöçıĞÜŞİÖÇ]\"\n",
        "    command_part = re.sub(pattern_new, \"\", command_part)\n",
        "    #print(command_part)\n",
        "    command_part = normalizer.normalize(command_part)\n",
        "    #print(command_part)\n",
        "    command_part = command_part.lower()\n",
        "    documents.append((command_part, label))\n",
        "    #print(documents)\n",
        "    tokens = tokenizer.tokenize(command_part)\n",
        "    words = [\n",
        "        stemmer.stem(token.content)\n",
        "        for token in tokens\n",
        "        if token.content not in turkish_stopwords\n",
        "    ]\n",
        "    #print(words)\n",
        "    all_words.extend(words)\n",
        "    #print(all_words)\n",
        "    #break\n",
        "\n",
        "random.shuffle(documents)"
      ],
      "metadata": {
        "id": "UDDCowGlGpZZ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.probability import FreqDist\n",
        "\n",
        "all_words = FreqDist(all_words)\n",
        "print(all_words)\n",
        "word_features = list(all_words.keys())[:400]\n",
        "print(word_features)"
      ],
      "metadata": {
        "id": "WhjpKWRyZmxV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a67a155-eef8-4b4e-9cf2-d80052f7b1de"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<FreqDist with 477 samples and 2231 outcomes>\n",
            "['çizg', 'formasyon', 'yap', 'v', 'çiz', 'ok', 'baş', 'yapıversen', 'üçgen', 'ol', 'oluş', 'şekl', 'çiziver', 'halin', 'gel', 'bur', 'üç', 'köşe', 'şekil', 'oluştur', 'acel', 'oluşturacak', 'hiza', 'oynay', 'voleybol', 'top', 'oyn', 'voleybolç', 'gerçekleştirme', 'gerekiyor', 'oynama', 'istirham', 'ediyor', 'ters', 'bir', 'sür', 'yapıl', 'oluşturul', 'çizs', 'drönelar', 'yapar', 'oldukç', 'müteşekkir', 'olur', 'oluşturma', 'emrediyor', 'yapma', 'ders', \"drone'ler\", 'ols', 'oyna', 'sürü', 'oynat', 'hadi', 'oynayal', 'iha', 'kullanarak', 'kenar', 'geometrik', 'çizdirme', 'sağl', 'güzel', 'don', 'düz', 'hat', 'elin', 'ak', 'dümt', 'ban', 'güç', 'zekan', 'harfi', 'attık', 'düş', 'dronelar', 'üçl', 'çektirmek', 'maksat', 'şekillen', 'şov', 'gösteri', 'başl', 'oyuncu', 'taklit', 'edecek', 'yarat', 'harfin', 'tasar', 'baka', 'geç', 'mot', 'maç', 'form', 'basiciz', 'uygu', 'düzg', 'çek', 'gerçekleş', 'çabuk', 'hemen', 'lan', 'çalış', 'can', 'turnuva', 'şampiyona', 'hatt', 'dizil', 'istiyor', 'ar', 'dizilir', 'yaps', 'dröne', 'göstersen', 'yapman', 'bekliyor', 'kesk', 'doğru', 'dönüş', 'oynaman', 'oyun', 'izleyebilir', 'miy', 'sıkıl', 'izlemek', 'ron', 'üzer', 'gitme', 'uç', 'uçuş', 'başlay', 'tek', 'olarak', 'gils', 'kron', 'devam', 'et', 'takip', 'yapan', 'biz', 'uçtuk', 'göster', 'voleybo', 'yer', 'al', 'izle', 'oluşturur', 'mus', 'lütfen', 'çizer', 'mis', 'dornelar', 'semil', 'keşk', 'drönelaerla', 'doğrusal', 'çizil', 'dizilme', 'tanrı', 'lütuf', 'iç', 'açı', 'topla', '180', 'derece', 'olan', 'dilek', 'doğr', 'yerleşip', 'ik', 'oluşan', 'bugünk', 'istek', 'dizilen', '3', 'kapa', 'el', 'ettik', 'ilk', 'hedef', 'oluşturmak', 'iler', 'ben', 'dröneu', 'oluşturan', 'sever', 'drone', 'dönedur', 'treeangu', 'var', 'tane', '2', 'vurur', 'diğer', 'gidip', 'geliyor', 'gözükme', 'oynayan', 'istiyör', 'oynar', 'mıs', 'dörencuk', 'vakıfbank', 'fatm', 'nokta', 'birleştiren', 'şeki', 'andıran', 'cis', 'kalem', 'değil', 'serg', 'sivr', 'bütün', 'bileşen', 'birbir', 'birleştirildik', 'köş', 'olma', 'zaval', 'şey', 'ara', 'dar', 'aç', 'olacak', 'birleşen', 'dik', 'büyük', 'işare', 'sahip', 'çokgen', 'köle', 'fırl', 'toplay', 'futbol', 'olun', 'yapılır', 'yapılacak', 'gelir', 'mi', 'döner', 'sen', 'dönmez', 'misk', 'başıiç', 'harek', 'dizayn', 'yin', 'oluşturman', 'kardeş', 'san', 'zahmet', 'vnin', 'gerek', 'birlik', 'koyar', 'rica', 'etse', 'duruş', 'acıs', 'istiyorumcizgiv', 'durs', 'konum', 'benzeyecek', 'koy', 'oluşturabilir', 'misinüçgenbir', 'yerleş', 'çiziyor', 'duyt', 'sıra', 'köycizgimisyo', 'yapmak', 'güveniyorumvdiriliş', 'ertuğrul', 'okun', 'tez', 'vakitteok', 'başıüçgen', 'on', 'oynasınvoleybol3', 'dur', 'karşı', 'olmüşvoleybolvoleybol', 'gerçek', 'aksin', 'kanıtlavoleybolsan', 'veriyor', 'onlar', 'ikna', 'etvoleybolvoleybol', 'görebilir', 'çizgi', 'çizme', 'lütfeder', 'misinvok', 'gerçekleştir', 'görev', 'çizebilir', 'hareket', 'gerçekleştirebilir', 'formasyonunuok', 'başıgörev', 'çizgidrönelar', 'ets', 'çizmen', 'uygun', 'gördümok', 'başıyapacak', 'algoritma', 'uçur', 'operasyon', 'tama', 'yanlış', 'yazıl', 'ekip', 'ait', 'karar', 'michael', 'gerçekleştirecek', 'tabi', 'taraf', 'verilen', 'getirecek', 'şun', 'gerçekleştirsen', 'sonuç', 'bul', 'yapabilir', 'adım', 'servis', 'spor', 'dalı', \"drone'leri\", 'çizdik', 'hizalan', 'aynı', 'hava', 'topu', 'benzer', 'güzergah', 'gir', 'çizgiçizgiv', 'yapamayan', 'warm', 'kaybetme', 'mahkum', 'kaybetmey', 'animasyon', 'oynayınvoleybolvoleybol', 'eda', 'erde', 'vargas', 'sıralan', 'vyi', 'git', 'uz', 'der', 'tep', 'ora', 'alal', 'bakıyor', 'gercekleştir', 'gels', 'saf', 'sıklaştır', 'bakal', 'sevgi', 'oynas', 'özg', 'kategori', 'özel', 'ism', 'sır', 'aşak', 'dizi', 'asker', 'la', 'minimum', 'figür', 'volleyball', 'döver', 'geçiş', 'alır', 'geçer', 'bebek', 'cano', 'beraber', 'vadi', 'vsi', 'kuş', 'göç', 'bermu', 'kalbim', 'saplan', 'show', 'tim', 'oynayıver', 'sade', '1', 'sabit']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_features(command):\n",
        "\n",
        "  command = normalizer.normalize(command)\n",
        "  tokens = tokenizer.tokenize(command)\n",
        "  words = [\n",
        "      stemmer.stem(token.content)\n",
        "      for token in tokens\n",
        "      if token.content not in turkish_stopwords\n",
        "  ]\n",
        "  features = {}\n",
        "\n",
        "  for w in word_features:\n",
        "    features[w] = (w in words)\n",
        "\n",
        "  return features"
      ],
      "metadata": {
        "id": "fvys4VQZZmuc"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "featuresets = [(find_features(command_part), label) for (command_part, label) in documents]\n",
        "command_with_label = [(command_part, label) for (command_part, label) in documents]"
      ],
      "metadata": {
        "id": "KIGxP2EiZmrU"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(len(featuresets) * 0.80)\n",
        "training_test = featuresets[:train_size]\n",
        "testing_set = featuresets[train_size:]\n",
        "testing_set_special = command_with_label[train_size:]\n",
        "classifier = nltk.NaiveBayesClassifier.train(training_test)\n",
        "classifier.train(training_test)\n",
        "\n",
        "i = 0\n",
        "for test_command in testing_set_special:\n",
        "  testing_state = [testing_set[i]]\n",
        "  accuracy = (nltk.classify.accuracy(classifier, testing_state)) * 100\n",
        "\n",
        "  if accuracy < 50:\n",
        "        print(\n",
        "            f\"command: {test_command[0]} predict label: {classifier.classify(find_features(test_command[0]))}  real label: {test_command[1]}\"\n",
        "        )\n",
        "  i += 1\n",
        "\n",
        "new_data_ = \"üç kenarlı bir şekil çizer misin.\"\n",
        "new_data = word_tokenize(new_data_)"
      ],
      "metadata": {
        "id": "jsyS9O2YZmma",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05f95313-6eef-427b-e874-60b6d9b4789e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "command: dröneları düz çizgi üzerine sırayla köycizgimisyonun drönelar ile v şekli yapmaktır sana güveniyorumvdiriliş ertuğrulun okunun başı gibi bir formasyon oluşturasın tez vakitteok başıüçgen diye bir şekil var ya onun şeklini oluştur predict label: Cizgi  real label: Üçgen\n",
            "command: donlar safları sıklaştırsın predict label: voleybol  real label: Cizgi\n",
            "command: bir de ters v gelir mi predict label: V  real label: Ok başı\n",
            "command: dik büyüktür işareti oluştur predict label: Cizgi  real label: Ok başı\n",
            "command: sana ters v formasyonunu çizmeni uygun gördümok başıyapacaksın üçgen formasyonunu predict label: V  real label: Üçgen\n",
            "command: v formasyonunun ters halini al predict label: V  real label: Ok başı\n",
            "command: voleybola hazır hale geçin predict label: Cizgi  real label: voleybol\n",
            "command: v çizsin donlar predict label: Ok başı  real label: V\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = nltk.NaiveBayesClassifier.train(training_test)\n",
        "prediction = classifier.classify(find_features(new_data_))\n",
        "print(\"Tahmin Sonucu:\", prediction)\n",
        "print(\"Naive Bayes Algo Accuracy percent: \", (nltk.classify.accuracy(classifier, testing_set))*100)\n",
        "#classifier.show_most_informative_features(15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKrnpWS2Z_N5",
        "outputId": "bc23985d-c513-4399-a736-838b3aa1abd8"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tahmin Sonucu: Üçgen\n",
            "Naive Bayes Algo Accuracy percent:  92.5925925925926\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.classify.scikitlearn import SklearnClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
        "\n",
        "MNB_classifier = SklearnClassifier(MultinomialNB())\n",
        "MNB_classifier.train(training_test)\n",
        "\n",
        "prediction = MNB_classifier.classify(find_features(new_data_))\n",
        "print(\"Tahmin Sonucu:\", prediction)\n",
        "print(\"MultinomialNB Algo Accuracy percent: \", (nltk.classify.accuracy(MNB_classifier, testing_set))*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWmB76eMZ_LD",
        "outputId": "2306a249-12e1-4d52-a7dc-7aa0cab6ca1d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tahmin Sonucu: Üçgen\n",
            "MultinomialNB Algo Accuracy percent:  89.81481481481481\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BernaulliNB_classifier = SklearnClassifier(BernoulliNB())\n",
        "BernaulliNB_classifier.train(training_test)\n",
        "\n",
        "prediction = BernaulliNB_classifier.classify(find_features(new_data_))\n",
        "print(\"Tahmin Sonucu:\", prediction)\n",
        "print(\"BernoulliNB Algo Accuracy percent: \", (nltk.classify.accuracy(BernaulliNB_classifier, testing_set))*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MisvX2ZuZ_Ib",
        "outputId": "b008e100-33da-41e8-a2ed-22f782e34b14"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tahmin Sonucu: Üçgen\n",
            "BernoulliNB Algo Accuracy percent:  92.5925925925926\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
        "\n",
        "\n",
        "LinearSVC_classifier = SklearnClassifier(LinearSVC())\n",
        "LinearSVC_classifier.train(training_test)\n",
        "\n",
        "prediction = LinearSVC_classifier.classify(find_features(new_data_))\n",
        "print(\"Tahmin Sonucu:\", prediction)\n",
        "print(\"BernoulliNB Algo Accuracy percent: \", (nltk.classify.accuracy(LinearSVC_classifier, testing_set))*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrW8cWHoZ_FV",
        "outputId": "2b8dc179-a3d8-4254-9d8e-61ea53a10244"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tahmin Sonucu: Üçgen\n",
            "BernoulliNB Algo Accuracy percent:  95.37037037037037\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LogisticRegression_classifier = SklearnClassifier(LogisticRegression())\n",
        "LogisticRegression_classifier.train(training_test)\n",
        "\n",
        "prediction = LogisticRegression_classifier.classify(find_features(new_data_))\n",
        "print(\"Tahmin Sonucu:\", prediction)\n",
        "print(\"LogisticRegression Algo Accuracy percent: \", (nltk.classify.accuracy(LogisticRegression_classifier, testing_set))*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22Q1JMVmaLBM",
        "outputId": "c7ec82b5-0904-4222-fdd6-61843b61831b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tahmin Sonucu: Üçgen\n",
            "LogisticRegression Algo Accuracy percent:  94.44444444444444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SGDClassifier = SklearnClassifier(SGDClassifier())\n",
        "SGDClassifier.train(training_test)\n",
        "\n",
        "prediction = SGDClassifier.classify(find_features(new_data_))\n",
        "print(\"Tahmin Sonucu:\", prediction)\n",
        "print(\"SGDClassifier Algo Accuracy percent: \", (nltk.classify.accuracy(SGDClassifier, testing_set))*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jn_2egnCaK3g",
        "outputId": "393c8e2e-3cad-419b-eec0-ef8e97cd52ec"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tahmin Sonucu: Üçgen\n",
            "SGDClassifier Algo Accuracy percent:  92.5925925925926\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class VoteClassifier(ClassifierI):\n",
        "  def __init__(self, *classifiers):\n",
        "    self.classifiers = classifiers\n",
        "\n",
        "  def classify(self, features):\n",
        "    votes = []\n",
        "    for c in self.classifiers:\n",
        "      v = c.classify(features)\n",
        "      votes.append(v)\n",
        "    return mode(votes)\n",
        "\n",
        "vote_classifier = VoteClassifier(classifier,\n",
        "                                  MNB_classifier,\n",
        "                                  BernaulliNB_classifier,\n",
        "                                  SGDClassifier,\n",
        "                                  LinearSVC_classifier,\n",
        "                                  LogisticRegression_classifier)\n",
        "\n",
        "prediction = vote_classifier.classify(find_features(new_data_))\n",
        "print(\"Tahmin Sonucu:\", prediction)\n",
        "print(\"vote_classifier accuracy percent:\", (nltk.classify.accuracy(vote_classifier, testing_set))*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhUC5L1eaTC9",
        "outputId": "d3317866-79b6-4bf1-9f3e-37f28865d87c"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tahmin Sonucu: Üçgen\n",
            "vote_classifier accuracy percent: 94.44444444444444\n"
          ]
        }
      ]
    }
  ]
}