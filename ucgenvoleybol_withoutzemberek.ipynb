{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvZ7CcueA2L2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(\"/content/output.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.classify import ClassifierI\n",
        "from statistics import mode\n",
        "import pickle"
      ],
      "metadata": {
        "id": "3xtGQ2eQA4xT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import os\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "documents = []\n",
        "\n",
        "for _, row in data.iterrows():\n",
        "    documents.append((word_tokenize(row['Command']), row[' Label']))\n",
        "print(documents)"
      ],
      "metadata": {
        "id": "mUHMzmK3A4vP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.probability import FreqDist\n",
        "\n",
        "all_words = []\n",
        "for doc, label in documents:\n",
        "  for w in doc:\n",
        "    all_words.append(w.lower())\n",
        "\n",
        "all_words = nltk.FreqDist(all_words)\n",
        "print(all_words.most_common(15))\n",
        "print(all_words[\"üçgen\"])\n",
        "\n",
        "word_features = list(all_words.keys())[:1000]"
      ],
      "metadata": {
        "id": "h25y6BfvA4so"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_features(document):\n",
        "\n",
        "  document = \" \".join(document) if isinstance(document, list) else document\n",
        "  words = word_tokenize(document)\n",
        "  features = {}\n",
        "\n",
        "  for w in word_features:\n",
        "    features[w] = (w in words)\n",
        "\n",
        "  return features"
      ],
      "metadata": {
        "id": "QjaYBIO5A4qi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "featuresets = [(find_features(rev), category) for (rev, category) in documents]"
      ],
      "metadata": {
        "id": "0OxYOSd8A4n9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(len(featuresets) * 0.75)\n",
        "training_test = featuresets[:train_size]\n",
        "testing_set = featuresets[train_size:]\n",
        "\n",
        "new_data_ = \"üç kenarlı bir şekil çizer misin.\"\n",
        "new_data = word_tokenize(new_data_)"
      ],
      "metadata": {
        "id": "y9GXbDl0A4lG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = nltk.NaiveBayesClassifier.train(training_test)\n",
        "prediction = classifier.classify(find_features(new_data))\n",
        "print(\"Tahmin Sonucu:\", prediction)\n",
        "print(\"Naive Bayes Algo Accuracy percent: \", (nltk.classify.accuracy(classifier, testing_set))*100)\n",
        "classifier.show_most_informative_features(15)"
      ],
      "metadata": {
        "id": "R0EOiSycA4gJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.classify.scikitlearn import SklearnClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
        "\n",
        "MNB_classifier = SklearnClassifier(MultinomialNB())\n",
        "MNB_classifier.train(training_test)\n",
        "\n",
        "prediction = MNB_classifier.classify(find_features(new_data))\n",
        "print(\"Tahmin Sonucu:\", prediction)\n",
        "print(\"MultinomialNB Algo Accuracy percent: \", (nltk.classify.accuracy(MNB_classifier, testing_set))*100)"
      ],
      "metadata": {
        "id": "n_6aQo_xA4cQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BernaulliNB_classifier = SklearnClassifier(BernoulliNB())\n",
        "BernaulliNB_classifier.train(training_test)\n",
        "\n",
        "prediction = BernaulliNB_classifier.classify(find_features(new_data))\n",
        "print(\"Tahmin Sonucu:\", prediction)\n",
        "print(\"BernoulliNB Algo Accuracy percent: \", (nltk.classify.accuracy(BernaulliNB_classifier, testing_set))*100)"
      ],
      "metadata": {
        "id": "nD93U5y-BLgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
        "\n",
        "\n",
        "LinearSVC_classifier = SklearnClassifier(LinearSVC())\n",
        "LinearSVC_classifier.train(training_test)\n",
        "\n",
        "prediction = LinearSVC_classifier.classify(find_features(new_data))\n",
        "print(\"Tahmin Sonucu:\", prediction)\n",
        "print(\"BernoulliNB Algo Accuracy percent: \", (nltk.classify.accuracy(LinearSVC_classifier, testing_set))*100)"
      ],
      "metadata": {
        "id": "kuYQssL4BLeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LogisticRegression_classifier = SklearnClassifier(LogisticRegression())\n",
        "LogisticRegression_classifier.train(training_test)\n",
        "\n",
        "prediction = LogisticRegression_classifier.classify(find_features(new_data))\n",
        "print(\"Tahmin Sonucu:\", prediction)\n",
        "print(\"LogisticRegression Algo Accuracy percent: \", (nltk.classify.accuracy(LogisticRegression_classifier, testing_set))*100)"
      ],
      "metadata": {
        "id": "8Z31oZKaBLbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SGDClassifier = SklearnClassifier(SGDClassifier())\n",
        "SGDClassifier.train(training_test)\n",
        "\n",
        "prediction = SGDClassifier.classify(find_features(new_data))\n",
        "print(\"Tahmin Sonucu:\", prediction)\n",
        "print(\"SGDClassifier Algo Accuracy percent: \", (nltk.classify.accuracy(SGDClassifier, testing_set))*100)"
      ],
      "metadata": {
        "id": "yeT0CZoZBWHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VoteClassifier(ClassifierI):\n",
        "  def __init__(self, *classifiers):\n",
        "    self.classifiers = classifiers\n",
        "\n",
        "  def classify(self, features):\n",
        "    votes = []\n",
        "    for c in self.classifiers:\n",
        "      v = c.classify(features)\n",
        "      votes.append(v)\n",
        "    return mode(votes)\n",
        "\n",
        "vote_classifier = VoteClassifier(classifier,\n",
        "                                  MNB_classifier,\n",
        "                                  BernaulliNB_classifier,\n",
        "                                  SGDClassifier,\n",
        "                                  LinearSVC_classifier,\n",
        "                                  LogisticRegression_classifier)\n",
        "\n",
        "prediction = vote_classifier.classify(find_features(new_data))\n",
        "print(\"Tahmin Sonucu:\", prediction)\n",
        "print(\"vote_classifier accuracy percent:\", (nltk.classify.accuracy(vote_classifier, testing_set))*100)"
      ],
      "metadata": {
        "id": "Fv0f4v6ABWE0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}